{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, sys, random, csv, json, shutil, subprocess, zipfile\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import List\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\n\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ðŸ–¥ï¸  Using device: {device}\")\n\n# Uncomment the next line the very first time you run the notebook\n!pip install -q transformers tensorboard scikit-learn rasterio\n\n# Clone SITS-BERT only once\nif not Path(\"/kaggle/working/SITS-BERT\").exists():\n    !git clone -q https://github.com/linlei1214/SITS-BERT.git /kaggle/working/SITS-BERT\nsys.path.append(\"/kaggle/working/SITS-BERT\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T19:33:48.135631Z","iopub.execute_input":"2025-06-05T19:33:48.135944Z","iopub.status.idle":"2025-06-05T19:34:01.953424Z","shell.execute_reply.started":"2025-06-05T19:33:48.135919Z","shell.execute_reply":"2025-06-05T19:34:01.952179Z"}},"outputs":[{"name":"stdout","text":"ðŸ–¥ï¸  Using device: cpu\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!mkdir -p checkpoints_pretrain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T19:34:01.955794Z","iopub.execute_input":"2025-06-05T19:34:01.956577Z","iopub.status.idle":"2025-06-05T19:34:02.212361Z","shell.execute_reply.started":"2025-06-05T19:34:01.956541Z","shell.execute_reply":"2025-06-05T19:34:02.210581Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!rm -r data/TimeSen2Crop/raw/TimeSen2Crop\n!mkdir -p data/TimeSen2Crop/raw\n!wget -O data/TimeSen2Crop/raw/TimeSen2Crop.zip https://rslab.disi.unitn.it/timesen2crop/TimeSen2Crop.zip\n!unzip -q data/TimeSen2Crop/raw/TimeSen2Crop.zip -d data/TimeSen2Crop/raw\n!rm -r data/TimeSen2Crop/raw/TimeSen2Crop.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T14:59:01.284841Z","iopub.execute_input":"2025-06-08T14:59:01.285142Z"}},"outputs":[{"name":"stdout","text":"rm: cannot remove 'data/TimeSen2Crop/raw/TimeSen2Crop': No such file or directory\n--2025-06-08 14:59:01--  https://rslab.disi.unitn.it/timesen2crop/TimeSen2Crop.zip\nResolving rslab.disi.unitn.it (rslab.disi.unitn.it)... 193.205.194.91\nConnecting to rslab.disi.unitn.it (rslab.disi.unitn.it)|193.205.194.91|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1079952573 (1.0G) [application/zip]\nSaving to: â€˜data/TimeSen2Crop/raw/TimeSen2Crop.zipâ€™\n\ndata/TimeSen2Crop/r 100%[===================>]   1.00G  10.4MB/s    in 1m 57s  \n\n2025-06-08 15:00:58 (8.83 MB/s) - â€˜data/TimeSen2Crop/raw/TimeSen2Crop.zipâ€™ saved [1079952573/1079952573]\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"BANDS: List[str] = [\"B02\", \"B03\", \"B04\", \"B05\", \"B08\", \"B11\"]  # Sentinel-2 L2A\nNBANDS                = len(BANDS)          # 6\nMAX_SEQ_LEN           = 24                  # always trim/pad to 24 dates\nFEATURES              = NBANDS + 1          # +1 for DOY  â‡’ 7-channel tensors\n\n# Where to put intermediate artefacts\nPRETRAIN_MANIFEST_CSV = Path(\"/kaggle/working/timesen2crop_pretrain.csv\")\nTMP_NPY_DIR           = Path(\"/kaggle/working/timesen2crop_npy\")\nTMP_NPY_DIR.mkdir(exist_ok=True, parents=True)\n\nFLAT_144_CSV = \"/kaggle/working/t2c_pretrain_flat.csv\"      # legacy (24Ã—6)\nFLAT_168_CSV = \"/kaggle/working/t2c_pretrain_flat_168.csv\"  # new  (24Ã—7)\n\n# Location of the raw TimeSen2Crop folder\nT2C_ROOT  = Path(\"data/TimeSen2Crop/raw/TimeSen2Crop\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:29:44.749765Z","iopub.execute_input":"2025-06-05T22:29:44.750142Z","iopub.status.idle":"2025-06-05T22:29:44.758287Z","shell.execute_reply.started":"2025-06-05T22:29:44.750102Z","shell.execute_reply":"2025-06-05T22:29:44.757502Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"FMT = \"{:.6f}\".format                # fixed-width float for the flat CSVs\n\ndef pad_or_crop(arr: np.ndarray, L: int) -> np.ndarray:\n    \"\"\"Trim an array with shape (T, C) to length L or 0-pad it.\"\"\"\n    if arr.shape[0] >= L:\n        return arr[:L]\n    pad = np.zeros((L - arr.shape[0], arr.shape[1]), dtype=arr.dtype)\n    return np.vstack([arr, pad])\n\ndef read_doy_vector(dates_path: Path) -> np.ndarray:\n    \"\"\"\n    Read <sample>/dates.csv and return a 1-D array of day-of-year values,\n    normalised to 0-1. If the file is missing or malformed â†’ empty array.\n    \"\"\"\n    if not dates_path.exists():\n        return np.array([], dtype=np.float32)\n\n    try:\n        dates = pd.read_csv(dates_path)[\"acquisition_date\"].astype(str)\n        doy   = dates.map(\n            lambda x: datetime.strptime(x, \"%Y%m%d\").timetuple().tm_yday\n        ).astype(np.float32) / 366.0\n        return doy.values\n    except Exception as err:                            # pragma: no cover\n        print(f\"âš ï¸  {dates_path}: {err}\")\n        return np.array([], dtype=np.float32)\n\ndef _rowfmt(arr: np.ndarray) -> list[str]:\n    \"\"\"Flatten & stringify a 2-D array for the flat CSVs.\"\"\"\n    return [FMT(x) for x in arr.flatten()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:29:44.759153Z","iopub.execute_input":"2025-06-05T22:29:44.759454Z","iopub.status.idle":"2025-06-05T22:29:44.784312Z","shell.execute_reply.started":"2025-06-05T22:29:44.759428Z","shell.execute_reply":"2025-06-05T22:29:44.783446Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def build_manifest(max_percent: int = -1) -> None:\n    \"\"\"\n    Walk the TimeSen2Crop tree, convert each sample to a (24, 7) tensor\n    (B02â€“B11 + DOY), save it as .npy, and create a manifest CSV.\n    \"\"\"\n    csv_files = [\n        f for f in T2C_ROOT.rglob(\"*.csv\")\n        if f.name.lower() != \"dates.csv\"\n    ]\n    total = len(csv_files)\n    if 0 < max_percent <= 100:\n        keep = max(1, int(total * max_percent / 100))\n        csv_files = csv_files[:keep]\n        print(f\"âš™ï¸  Processing {keep}/{total} files ({max_percent}%)\")\n    else:\n        print(f\"âš™ï¸  Processing all {total} files\")\n\n    manifest_rows = []\n\n    for csv_path in tqdm(csv_files, desc=\"TimeSen2Crop\"):\n        df = pd.read_csv(csv_path)\n\n        # Drop QA flag if present\n        if \"Flag\" in df.columns:\n            df = df.drop(columns=[\"Flag\"])\n\n        # --------------------- spectral matrix ----------------------------\n        src_cols = df.columns.tolist()\n        col_map  = {c.lstrip(\"0\"): i for i, c in enumerate(src_cols)}\n\n        spec = np.zeros((df.shape[0], NBANDS), np.float32)  # (T, 6)\n        for tgt, band in enumerate(BANDS):\n            src = col_map.get(band.replace(\"B0\", \"B\").lstrip(\"0\"), -1)\n            if src != -1:\n                spec[:, tgt] = np.clip(df.iloc[:, src].values / 1e4, 0, 1)\n\n        # --------------------------- DOY ---------------------------------\n        doy = read_doy_vector(csv_path.parent / \"dates.csv\")\n        if doy.size != spec.shape[0]:\n            doy = np.zeros(spec.shape[0], np.float32)       # fallback\n\n        spec_doy = np.hstack([spec, doy[:, None]])          # (T, 7)\n\n        # ------ trim/pad to 24 dates & save --------------------------------\n        arr = pad_or_crop(spec_doy, MAX_SEQ_LEN).astype(np.float32)\n        rel = csv_path.relative_to(T2C_ROOT).with_suffix(\".npy\")\n        out = TMP_NPY_DIR / rel\n        out.parent.mkdir(parents=True, exist_ok=True)\n        np.save(out, arr)\n\n        manifest_rows.append({\"file\": str(out), \"label\": -1, \"date\": \"\"})\n        os.remove(csv_path)                                 # reclaim space\n\n    pd.DataFrame(manifest_rows).to_csv(PRETRAIN_MANIFEST_CSV, index=False)\n    print(f\"âœ”ï¸  Manifest saved to {PRETRAIN_MANIFEST_CSV} \"\n          f\"({len(manifest_rows):,} samples)\")\n\n# Kick it off (set max_percent to e.g. 10 for a quick smoke-test)\nbuild_manifest(max_percent=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:29:44.786477Z","iopub.execute_input":"2025-06-05T22:29:44.786787Z","iopub.status.idle":"2025-06-05T23:21:25.243738Z","shell.execute_reply.started":"2025-06-05T22:29:44.786764Z","shell.execute_reply":"2025-06-05T23:21:25.241510Z"}},"outputs":[{"name":"stdout","text":"âš™ï¸  Processing all 1212224 files\n","output_type":"stream"},{"name":"stderr","text":"TimeSen2Crop: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1212224/1212224 [51:25<00:00, 392.87it/s] \n","output_type":"stream"},{"name":"stdout","text":"âœ”ï¸  Manifest saved to /kaggle/working/timesen2crop_pretrain.csv (1,212,224 samples)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print(\"\\nðŸ“  Writing flattened CSVs â€¦\")\n\n# 4.1â€‚144 floats (6 bands Ã— 24)\nwith open(FLAT_144_CSV, \"w\", newline=\"\") as fout:\n    wr = csv.writer(fout)\n    for f in tqdm(pd.read_csv(PRETRAIN_MANIFEST_CSV)[\"file\"], desc=\"â†’ 144-col\"):\n        wr.writerow(_rowfmt(np.load(f)[:, :NBANDS]))\nprint(f\"âœ”ï¸  144-wide CSV   â†’ {FLAT_144_CSV}\")\n\n# 4.2â€‚168 floats (6 bands + DOY Ã— 24)\nwith open(FLAT_168_CSV, \"w\", newline=\"\") as fout:\n    wr = csv.writer(fout)\n    for f in tqdm(pd.read_csv(PRETRAIN_MANIFEST_CSV)[\"file\"], desc=\"â†’ 168-col\"):\n        wr.writerow(_rowfmt(np.load(f)))\nprint(f\"âœ”ï¸  168-wide CSV   â†’ {FLAT_168_CSV}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:21:25.246787Z","iopub.execute_input":"2025-06-05T23:21:25.247189Z","iopub.status.idle":"2025-06-05T23:36:05.366858Z","shell.execute_reply.started":"2025-06-05T23:21:25.247147Z","shell.execute_reply":"2025-06-05T23:36:05.365770Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“  Writing flattened CSVs â€¦\n","output_type":"stream"},{"name":"stderr","text":"â†’ 144-col: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1212224/1212224 [08:06<00:00, 2494.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ”ï¸  144-wide CSV   â†’ /kaggle/working/t2c_pretrain_flat.csv\n","output_type":"stream"},{"name":"stderr","text":"â†’ 168-col: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1212224/1212224 [06:31<00:00, 3099.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ”ï¸  168-wide CSV   â†’ /kaggle/working/t2c_pretrain_flat_168.csv\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# Update pretraining.py to your CSV/checkpoint paths, bands, etc.\n!sed -i \"s#dataset_path = .*#dataset_path = '/kaggle/working/t2c_pretrain_flat_168.csv'#\"   /kaggle/working/SITS-BERT/code/pretraining.py\n!sed -i \"s#pretrain_path = .*#pretrain_path = '/kaggle/working/checkpoints_pretrain/'#\"  /kaggle/working/SITS-BERT/code/pretraining.py\n!sed -i \"s#num_features = .*#num_features = 6#\"   /kaggle/working/SITS-BERT/code/pretraining.py\n!sed -i \"s#max_length = .*#max_length = 24#\"      /kaggle/working/SITS-BERT/code/pretraining.py\n!sed -i \"s#batch_size = .*#batch_size = 256#\"     /kaggle/working/SITS-BERT/code/pretraining.py\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:36:05.387963Z","iopub.execute_input":"2025-06-05T23:36:05.388229Z","iopub.status.idle":"2025-06-05T23:36:06.228327Z","shell.execute_reply.started":"2025-06-05T23:36:05.388207Z","shell.execute_reply":"2025-06-05T23:36:06.226975Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"!python /kaggle/working/SITS-BERT/code/pretraining.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:55:34.014942Z","iopub.execute_input":"2025-06-05T23:55:34.015636Z","iopub.status.idle":"2025-06-05T23:55:37.951588Z","shell.execute_reply.started":"2025-06-05T23:55:34.015574Z","shell.execute_reply":"2025-06-05T23:55:37.950417Z"}},"outputs":[{"name":"stdout","text":"^C\n2025-06-05 23:55:37.685347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749167737.713865     240 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749167737.722193     240 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":37}]}