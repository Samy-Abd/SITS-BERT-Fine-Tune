{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12174021,"sourceType":"datasetVersion","datasetId":7667349},{"sourceId":427712,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":348675,"modelId":369932}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python\n# ============================================================\n#  SITS-BERT  ·  California-Labeled  ·  6-band data prep\n# ------------------------------------------------------------\n#  Reads  : /kaggle/input/california-labeled/{Train,Validate,Test}.csv\n#  Writes : /kaggle/working/data/6_features_{Train,Validate,Test}.csv\n# ------------------------------------------------------------\n#  Each output row = 24 × 7 floats  (B1-6 + DOY)  +  label\n# ============================================================\n\nimport csv, subprocess, sys, shutil, random\nfrom pathlib import Path\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T18:47:09.722731Z","iopub.execute_input":"2025-06-17T18:47:09.722922Z","iopub.status.idle":"2025-06-17T18:47:09.730090Z","shell.execute_reply.started":"2025-06-17T18:47:09.722905Z","shell.execute_reply":"2025-06-17T18:47:09.729255Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ───────────────────────────────────\n# 0 · CONFIG\n# ───────────────────────────────────\nSEED       = 42\nSRC_DIR    = Path(\"/kaggle/input/california-labeled\")\nDST_DIR    = Path(\"/kaggle/working/data\")\nSITS_REPO  = Path(\"/kaggle/working/SITS-BERT\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T18:47:09.731440Z","iopub.execute_input":"2025-06-17T18:47:09.731632Z","iopub.status.idle":"2025-06-17T18:47:09.750564Z","shell.execute_reply.started":"2025-06-17T18:47:09.731616Z","shell.execute_reply":"2025-06-17T18:47:09.749823Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!git clone -q https://github.com/linlei1214/SITS-BERT.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T18:47:09.751316Z","iopub.execute_input":"2025-06-17T18:47:09.751506Z","iopub.status.idle":"2025-06-17T18:47:10.714540Z","shell.execute_reply.started":"2025-06-17T18:47:09.751490Z","shell.execute_reply":"2025-06-17T18:47:10.713500Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!ls SITS-BERT/checkpoints/pretrain/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T18:47:10.715572Z","iopub.execute_input":"2025-06-17T18:47:10.715845Z","iopub.status.idle":"2025-06-17T18:47:10.836962Z","shell.execute_reply.started":"2025-06-17T18:47:10.715817Z","shell.execute_reply":"2025-06-17T18:47:10.836056Z"}},"outputs":[{"name":"stdout","text":"checkpoint.bert.pth\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!mkdir checkpoints_finetune","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T18:47:10.839469Z","iopub.execute_input":"2025-06-17T18:47:10.840074Z","iopub.status.idle":"2025-06-17T18:47:10.959577Z","shell.execute_reply.started":"2025-06-17T18:47:10.840032Z","shell.execute_reply":"2025-06-17T18:47:10.958523Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!python /kaggle/working/SITS-BERT/code/finetuning.py \\\n  --file_path /kaggle/input/california-labeled/ \\\n  --pretrain_path SITS-BERT/checkpoints/pretrain/ \\\n  --finetune_path /kaggle/working/checkpoints_finetune/ \\\n  --num_features 10 \\\n  --max_length 64 \\\n  --num_classes 13 \\\n  --epochs 100 \\\n  --batch_size 128 \\\n  --hidden_size 256 \\\n  --layers 3 \\\n  --attn_heads 8 \\\n  --learning_rate 2e-4 \\\n  --dropout 0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T18:47:10.960614Z","iopub.execute_input":"2025-06-17T18:47:10.960855Z","iopub.status.idle":"2025-06-17T18:51:29.951480Z","shell.execute_reply.started":"2025-06-17T18:47:10.960828Z","shell.execute_reply":"2025-06-17T18:51:29.950694Z"}},"outputs":[{"name":"stdout","text":"2025-06-17 18:47:17.997347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750186038.199726      79 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750186038.254220      79 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading Data sets...\ntraining samples: 1300, validation samples: 1300, testing samples: 318588\nCreating Dataloader...\nInitialing SITS-BERT...\nLoading pre-trained model parameters...\nCreating Downstream Task Trainer...\nFine-tuning SITS-BERT...\nEP0, train_OA=23.38, train_Kappa=0.170, validate_OA=43.46, validate_Kappa=0.388\nEP:0 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP1, train_OA=53.31, train_Kappa=0.494, validate_OA=74.38, validate_Kappa=0.723\nEP:1 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP2, train_OA=76.38, train_Kappa=0.744, validate_OA=84.54, validate_Kappa=0.833\nEP:2 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP3, train_OA=85.38, train_Kappa=0.842, validate_OA=87.46, validate_Kappa=0.864\nEP:3 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP4, train_OA=88.31, train_Kappa=0.873, validate_OA=88.46, validate_Kappa=0.875\nEP:4 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP5, train_OA=90.23, train_Kappa=0.894, validate_OA=89.54, validate_Kappa=0.887\nEP:5 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP6, train_OA=91.00, train_Kappa=0.902, validate_OA=90.23, validate_Kappa=0.894\nEP:6 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP7, train_OA=92.08, train_Kappa=0.914, validate_OA=91.15, validate_Kappa=0.904\nEP:7 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP8, train_OA=93.31, train_Kappa=0.927, validate_OA=92.00, validate_Kappa=0.913\nEP:8 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP9, train_OA=93.92, train_Kappa=0.934, validate_OA=92.69, validate_Kappa=0.921\nEP:9 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP10, train_OA=95.00, train_Kappa=0.946, validate_OA=93.23, validate_Kappa=0.927\nEP:10 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP11, train_OA=94.62, train_Kappa=0.942, validate_OA=93.46, validate_Kappa=0.929\nEP:11 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP12, train_OA=95.23, train_Kappa=0.948, validate_OA=93.31, validate_Kappa=0.927\nEP13, train_OA=95.54, train_Kappa=0.952, validate_OA=94.08, validate_Kappa=0.936\nEP:13 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP14, train_OA=95.38, train_Kappa=0.950, validate_OA=93.85, validate_Kappa=0.933\nEP15, train_OA=95.85, train_Kappa=0.955, validate_OA=93.77, validate_Kappa=0.932\nEP16, train_OA=96.00, train_Kappa=0.957, validate_OA=94.00, validate_Kappa=0.935\nEP17, train_OA=96.92, train_Kappa=0.967, validate_OA=94.15, validate_Kappa=0.937\nEP:17 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP18, train_OA=97.00, train_Kappa=0.968, validate_OA=94.38, validate_Kappa=0.939\nEP:18 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP19, train_OA=96.85, train_Kappa=0.966, validate_OA=94.38, validate_Kappa=0.939\nEP20, train_OA=97.23, train_Kappa=0.970, validate_OA=94.62, validate_Kappa=0.942\nEP:20 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP21, train_OA=97.62, train_Kappa=0.974, validate_OA=94.69, validate_Kappa=0.943\nEP:21 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP22, train_OA=97.54, train_Kappa=0.973, validate_OA=94.85, validate_Kappa=0.944\nEP:22 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP23, train_OA=97.69, train_Kappa=0.975, validate_OA=95.08, validate_Kappa=0.947\nEP:23 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP24, train_OA=97.92, train_Kappa=0.977, validate_OA=94.77, validate_Kappa=0.943\nEP25, train_OA=97.54, train_Kappa=0.973, validate_OA=95.15, validate_Kappa=0.947\nEP:25 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP26, train_OA=98.23, train_Kappa=0.981, validate_OA=95.08, validate_Kappa=0.947\nEP27, train_OA=98.08, train_Kappa=0.979, validate_OA=95.31, validate_Kappa=0.949\nEP:27 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP28, train_OA=98.46, train_Kappa=0.983, validate_OA=95.38, validate_Kappa=0.950\nEP:28 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP29, train_OA=98.38, train_Kappa=0.982, validate_OA=95.46, validate_Kappa=0.951\nEP:29 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP30, train_OA=98.54, train_Kappa=0.984, validate_OA=95.46, validate_Kappa=0.951\nEP31, train_OA=98.54, train_Kappa=0.984, validate_OA=95.46, validate_Kappa=0.951\nEP32, train_OA=98.69, train_Kappa=0.986, validate_OA=95.54, validate_Kappa=0.952\nEP:32 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP33, train_OA=99.15, train_Kappa=0.991, validate_OA=95.23, validate_Kappa=0.948\nEP34, train_OA=98.77, train_Kappa=0.987, validate_OA=94.85, validate_Kappa=0.944\nEP35, train_OA=99.00, train_Kappa=0.989, validate_OA=95.54, validate_Kappa=0.952\nEP36, train_OA=99.31, train_Kappa=0.992, validate_OA=95.46, validate_Kappa=0.951\nEP37, train_OA=99.46, train_Kappa=0.994, validate_OA=95.31, validate_Kappa=0.949\nEP38, train_OA=99.69, train_Kappa=0.997, validate_OA=95.38, validate_Kappa=0.950\nEP39, train_OA=99.38, train_Kappa=0.993, validate_OA=95.31, validate_Kappa=0.949\nEP40, train_OA=99.46, train_Kappa=0.994, validate_OA=95.46, validate_Kappa=0.951\nEP41, train_OA=99.46, train_Kappa=0.994, validate_OA=95.31, validate_Kappa=0.949\nEP42, train_OA=99.46, train_Kappa=0.994, validate_OA=95.08, validate_Kappa=0.947\nEP43, train_OA=99.77, train_Kappa=0.997, validate_OA=95.46, validate_Kappa=0.951\nEP44, train_OA=99.69, train_Kappa=0.997, validate_OA=95.31, validate_Kappa=0.949\nEP45, train_OA=99.69, train_Kappa=0.997, validate_OA=95.54, validate_Kappa=0.952\nEP46, train_OA=99.69, train_Kappa=0.997, validate_OA=95.31, validate_Kappa=0.949\nEP47, train_OA=99.85, train_Kappa=0.998, validate_OA=95.46, validate_Kappa=0.951\nEP48, train_OA=99.85, train_Kappa=0.998, validate_OA=95.54, validate_Kappa=0.952\nEP49, train_OA=99.77, train_Kappa=0.997, validate_OA=95.46, validate_Kappa=0.951\nEP50, train_OA=99.85, train_Kappa=0.998, validate_OA=95.38, validate_Kappa=0.950\nEP51, train_OA=99.62, train_Kappa=0.996, validate_OA=95.85, validate_Kappa=0.955\nEP:51 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP52, train_OA=99.46, train_Kappa=0.994, validate_OA=95.23, validate_Kappa=0.948\nEP53, train_OA=99.69, train_Kappa=0.997, validate_OA=95.31, validate_Kappa=0.949\nEP54, train_OA=99.85, train_Kappa=0.998, validate_OA=95.62, validate_Kappa=0.953\nEP55, train_OA=99.92, train_Kappa=0.999, validate_OA=95.62, validate_Kappa=0.953\nEP56, train_OA=99.85, train_Kappa=0.998, validate_OA=95.46, validate_Kappa=0.951\nEP57, train_OA=99.92, train_Kappa=0.999, validate_OA=95.77, validate_Kappa=0.954\nEP58, train_OA=99.77, train_Kappa=0.997, validate_OA=95.92, validate_Kappa=0.956\nEP:58 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP59, train_OA=100.00, train_Kappa=1.000, validate_OA=95.77, validate_Kappa=0.954\nEP60, train_OA=100.00, train_Kappa=1.000, validate_OA=95.85, validate_Kappa=0.955\nEP61, train_OA=99.92, train_Kappa=0.999, validate_OA=95.54, validate_Kappa=0.952\nEP62, train_OA=99.92, train_Kappa=0.999, validate_OA=95.77, validate_Kappa=0.954\nEP63, train_OA=99.92, train_Kappa=0.999, validate_OA=95.62, validate_Kappa=0.953\nEP64, train_OA=100.00, train_Kappa=1.000, validate_OA=95.46, validate_Kappa=0.951\nEP65, train_OA=100.00, train_Kappa=1.000, validate_OA=95.77, validate_Kappa=0.954\nEP66, train_OA=100.00, train_Kappa=1.000, validate_OA=95.38, validate_Kappa=0.950\nEP67, train_OA=100.00, train_Kappa=1.000, validate_OA=95.85, validate_Kappa=0.955\nEP68, train_OA=100.00, train_Kappa=1.000, validate_OA=95.46, validate_Kappa=0.951\nEP69, train_OA=100.00, train_Kappa=1.000, validate_OA=96.00, validate_Kappa=0.957\nEP:69 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP70, train_OA=100.00, train_Kappa=1.000, validate_OA=95.92, validate_Kappa=0.956\nEP71, train_OA=100.00, train_Kappa=1.000, validate_OA=95.62, validate_Kappa=0.953\nEP72, train_OA=100.00, train_Kappa=1.000, validate_OA=95.92, validate_Kappa=0.956\nEP73, train_OA=100.00, train_Kappa=1.000, validate_OA=96.08, validate_Kappa=0.958\nEP:73 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP74, train_OA=100.00, train_Kappa=1.000, validate_OA=96.08, validate_Kappa=0.958\nEP75, train_OA=99.85, train_Kappa=0.998, validate_OA=96.00, validate_Kappa=0.957\nEP76, train_OA=100.00, train_Kappa=1.000, validate_OA=96.23, validate_Kappa=0.959\nEP:76 Model Saved on: /kaggle/working/checkpoints_finetune/checkpoint.tar\nEP77, train_OA=99.92, train_Kappa=0.999, validate_OA=95.69, validate_Kappa=0.953\nEP78, train_OA=100.00, train_Kappa=1.000, validate_OA=95.92, validate_Kappa=0.956\nEP79, train_OA=100.00, train_Kappa=1.000, validate_OA=95.85, validate_Kappa=0.955\nEP80, train_OA=100.00, train_Kappa=1.000, validate_OA=95.77, validate_Kappa=0.954\nEP81, train_OA=100.00, train_Kappa=1.000, validate_OA=95.77, validate_Kappa=0.954\nEP82, train_OA=100.00, train_Kappa=1.000, validate_OA=95.92, validate_Kappa=0.956\nEP83, train_OA=100.00, train_Kappa=1.000, validate_OA=96.08, validate_Kappa=0.958\nEP84, train_OA=100.00, train_Kappa=1.000, validate_OA=95.92, validate_Kappa=0.956\nEP85, train_OA=100.00, train_Kappa=1.000, validate_OA=96.15, validate_Kappa=0.958\nEP86, train_OA=100.00, train_Kappa=1.000, validate_OA=96.08, validate_Kappa=0.958\nEP87, train_OA=100.00, train_Kappa=1.000, validate_OA=96.00, validate_Kappa=0.957\nEP88, train_OA=100.00, train_Kappa=1.000, validate_OA=95.85, validate_Kappa=0.955\nEP89, train_OA=100.00, train_Kappa=1.000, validate_OA=95.69, validate_Kappa=0.953\nEP90, train_OA=100.00, train_Kappa=1.000, validate_OA=95.92, validate_Kappa=0.956\nEP91, train_OA=100.00, train_Kappa=1.000, validate_OA=96.00, validate_Kappa=0.957\nEP92, train_OA=100.00, train_Kappa=1.000, validate_OA=95.69, validate_Kappa=0.953\nEP93, train_OA=100.00, train_Kappa=1.000, validate_OA=96.00, validate_Kappa=0.957\nEP94, train_OA=100.00, train_Kappa=1.000, validate_OA=95.85, validate_Kappa=0.955\nEP95, train_OA=100.00, train_Kappa=1.000, validate_OA=96.00, validate_Kappa=0.957\nEP96, train_OA=100.00, train_Kappa=1.000, validate_OA=96.08, validate_Kappa=0.958\nEP97, train_OA=100.00, train_Kappa=1.000, validate_OA=96.08, validate_Kappa=0.958\nEP98, train_OA=100.00, train_Kappa=1.000, validate_OA=96.00, validate_Kappa=0.957\nEP99, train_OA=100.00, train_Kappa=1.000, validate_OA=96.15, validate_Kappa=0.958\n\n\n\n\nTesting SITS-BERT...\nEP:76 Model loaded from: /kaggle/working/checkpoints_finetune/checkpoint.tar\ntest_OA = 94.18, test_kappa = 0.932, test_AA = 0.953\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# %matplotlib inline\n\n# import sys, inspect, csv, numpy as np, torch\n# from pathlib import Path\n# from torch.utils.data import Dataset, DataLoader\n# from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score\n# import matplotlib.pyplot as plt\n\n# # ───────────────────────────── Configuration ──────────────────────────────\n# ROOT       = Path(\"/kaggle/working\")\n# CSV_TEST   = Path(\"/kaggle/input/california-labeled/Test.csv\")\n# CKPT_FILE  = ROOT / \"checkpoints_finetune\" / \"checkpoint.tar\"\n# SITS_REPO  = ROOT / \"SITS-BERT\" / \"code\"\n# BATCH_SIZE = 128\n# WINDOW_LEN = 64\n# STRIDE     = 1   # same as during training\n# DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # ─────────── Add repo to path & import ────────────────────────────────────\n# sys.path.append(str(SITS_REPO))\n# from model.classification_model import SBERTClassification\n# from model.bert                 import SBERT\n\n# # ─────────── Build SBERT helper ──────────────────────────────────────────\n# _sig = inspect.signature(SBERT.__init__)\n# def make_sbert(num_features: int) -> torch.nn.Module:\n#     base = {\n#         \"num_features\": num_features,\n#         \"hidden\":       256,\n#         \"n_layers\":     3,\n#         \"attn_heads\":   8,\n#         \"dropout\":      0.1,\n#     }\n#     kwargs = {k: v for k, v in base.items() if k in _sig.parameters}\n#     if (missing := [p.name for p in _sig.parameters.values()\n#                     if p.default is inspect._empty\n#                        and p.name not in kwargs\n#                        and p.name != \"self\"]):\n#         raise RuntimeError(f\"❌ Missing SBERT init args: {missing}\")\n#     return SBERT(**kwargs)\n\n# # ─────────── Sliding-window Dataset ────────────────────────────────────\n# class WindowedDataset(Dataset):\n#     def __init__(self, path: Path, win_len: int = WINDOW_LEN, stride: int = STRIDE):\n#         rows = list(csv.reader(path.open()))\n#         self.x, self.doy, self.mask, self.y = [], [], [], []\n\n#         for r in rows:\n#             if not r: \n#                 continue\n#             arr   = np.asarray(r[:-1], dtype=np.float32)\n#             label = int(r[-1])\n#             n_feat = 11       # 10 bands + DOY\n#             spec   = n_feat-1\n#             T      = arr.size // n_feat\n\n#             # compute start indices\n#             if T < win_len:\n#                 starts = [0]\n#             else:\n#                 starts = list(range(0, T - win_len + 1, stride))\n#                 if (T - win_len) % stride != 0:\n#                     starts.append(T - win_len)\n\n#             for s in starts:\n#                 block = arr[s*n_feat : s*n_feat + win_len*n_feat]\n#                 real = min(win_len, block.size//n_feat)\n#                 if block.size < win_len*n_feat:\n#                     pad = np.zeros(win_len*n_feat - block.size, dtype=np.float32)\n#                     block = np.concatenate([block, pad], axis=0)\n\n#                 seq = block.reshape(win_len, n_feat)\n#                 self.x.append(seq[:, :spec] / 10000.0)\n#                 self.doy.append(seq[:, spec].astype(np.int64))\n#                 m = np.zeros(win_len, bool)\n#                 m[:real] = True\n#                 self.mask.append(m)\n#                 self.y.append(label)\n\n#         # tensorify\n#         self.x    = torch.tensor(np.stack(self.x),    dtype=torch.float32)\n#         self.doy  = torch.tensor(np.stack(self.doy),  dtype=torch.long)\n#         self.mask = torch.tensor(np.stack(self.mask), dtype=torch.bool)\n#         self.y    = torch.tensor(self.y,              dtype=torch.long)\n#         print(f\"✅ Loaded {len(self.y):,} windows \"\n#               f\"(each {win_len} steps of 10 bands+DOY)\")\n\n#     def __len__(self):\n#         return len(self.y)\n\n#     def __getitem__(self, i):\n#         return self.x[i], self.doy[i], self.mask[i], self.y[i]\n\n# # ─────────── Build dataset & loader ─────────────────────────────────────\n# ds     = WindowedDataset(CSV_TEST, win_len=WINDOW_LEN, stride=STRIDE)\n# loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False)\n\n# # ─────────── Build model & load checkpoint ───────────────────────────────\n# sbert = make_sbert(ds.x.size(-1))\n# model = SBERTClassification(sbert, int(ds.y.max()+1)).to(DEVICE)\n# ckpt  = torch.load(CKPT_FILE, map_location=DEVICE)\n# model.load_state_dict(ckpt[\"model_state_dict\"], strict=True)\n# model.eval()\n\n# # ─────────── Inference at window-level ───────────────────────────────────\n# y_true, y_pred = [], []\n# with torch.no_grad():\n#     pe_len = model.sbert.embedding.position.pe.size(0)\n#     for xb, doy, mask, yb in loader:\n#         xb   = xb.to(DEVICE)\n#         doy  = torch.clamp(doy.to(DEVICE) - 1, 0, pe_len - 1)\n#         mask = mask.to(DEVICE)\n#         logits = model(xb, doy, mask)  # [B, C]\n#         preds  = logits.argmax(dim=1).cpu().tolist()\n#         y_pred.extend(preds)\n#         y_true.extend(yb.tolist())\n\n# # ─────────── Metrics ──────────────────────────────────────────────────────\n# oa    = accuracy_score(y_true, y_pred) * 100\n# kappa = cohen_kappa_score(y_true, y_pred)\n# report = classification_report(y_true, y_pred, digits=4, zero_division=0)\n# print(f\"\\nTest OA   = {oa:.2f}%\")\n# print(f\"Test κ    = {kappa:.3f}\")\n# print(report)\n\n# # ─────────── Confusion matrix ─────────────────────────────────────────────\n# cm = confusion_matrix(y_true, y_pred)\n# plt.figure(figsize=(10, 8))\n# try:\n#     import seaborn as sns\n#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n# except ImportError:\n#     plt.imshow(cm, interpolation=\"nearest\", aspect=\"auto\")\n# plt.title(\"Window-level SITS-BERT Confusion Matrix\")\n# plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T18:51:29.952536Z","iopub.execute_input":"2025-06-17T18:51:29.952777Z","iopub.status.idle":"2025-06-17T18:51:29.959715Z","shell.execute_reply.started":"2025-06-17T18:51:29.952749Z","shell.execute_reply":"2025-06-17T18:51:29.958930Z"}},"outputs":[],"execution_count":7}]}